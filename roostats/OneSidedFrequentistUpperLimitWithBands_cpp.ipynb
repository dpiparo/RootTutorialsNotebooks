{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#One-Sided Frequentist Upper Limit With Bands\n",
    "\n",
    "*Author: Kyle Cranmer.\n",
    "Contributions from Haichen Wang and Daniel Whiteson. \n",
    "Date: Dec. 2010 - Feb. 2011.\n",
    "Translated to notebook by Enric Tejedor and Danilo Piparo, 2015\n",
    "v1. Jan 28*\n",
    "\n",
    "This is a standard demo that can be used with any ROOT file prepared in the standard way. You need to specify:\n",
    "- Name for input ROOT file.\n",
    "- Name of workspace inside ROOT file that holds model and data.\n",
    "- Name of ModelConfig that specifies details for calculator tools.\n",
    "- Name of dataset.\n",
    "\n",
    "With default parameters the macro will attempt to run the standard hist2workspace example and read the ROOT file that it produces.\n",
    "\n",
    "The first ~100 lines define a new test statistic, then the main code starts. You may want to control:\n",
    "- `double confidenceLevel = 0.95;`\n",
    "- `int nPointsToScan = 30;`\n",
    "- `int nToyMC = 200;`\n",
    "\n",
    "This uses a modified version of the profile likelihood ratio as a test statistic for upper limits (eg. test stat = 0 if muhat>mu).\n",
    "\n",
    "Based on the observed data, one defines a set of parameter points to be tested based on the value of the parameter of interest and the conditional MLE (eg. profiled) values of the nuisance parameters.\n",
    "\n",
    "At each parameter point, pseudo-experiments are generated using this fixed reference model and then the test statistic is evaluated. Note, the nuisance parameters are floating in the fits. For each point, the threshold that defines the 95% acceptance region is found. This forms a \"Confidence Belt\".\n",
    "\n",
    "After constructing the confidence belt, one can find the confidence interval for any particular dataset by finding the intersection of the observed test statistic and the confidence belt. First this is done on the observed data to get an observed 1-sided upper limit.\n",
    "\n",
    "Finally, the expected limit and bands (from background-only) are formed by generating background-only data and finding the upper limit. This is done by hand for now, it will later be part of the RooStats tools.\n",
    "\n",
    "On a technical note, this technique is NOT the Feldman-Cousins technique, because that is a 2-sided interval BY DEFINITION. However, like the Feldman-Cousins technique this is a Neyman-Construction. For technical reasons the easiest way to implement this right now is to use the FeldmanCousins tool and then change the test statistic that it is using.\n",
    "\n",
    "Building the confidence belt can be computationally expensive. Once it is built, one could save it to a file and use it in a separate step.\n",
    "\n",
    "We can use PROOF to speed things along in parallel; however, the test statistic has to be installed on the workers so either turn off PROOF or include the modified test statistic in your `$ROOTSYS/roofit/roostats/inc` directory,\n",
    "add the additional line to the `LinkDef.h` file, and recompile ROOT.\n",
    "\n",
    "Note, if you have a boundary on the parameter of interest (e.g. cross-section) the threshold on the one-sided test statistic starts off very small because we are only including downward fluctuations.  You can see the threshold in these printouts:\n",
    "\n",
    "`[#0] PROGRESS:Generation -- generated toys: 500 / 999\n",
    "NeymanConstruction: Prog: 12/50 total MC = 39 this test stat = 0\n",
    " SigXsecOverSM=0.69 alpha_syst1=0.136515 alpha_syst3=0.425415 beta_syst2=1.08496 [-1e+30, 0.011215]in interval = 1`\n",
    "\n",
    "This tells you the values of the parameters geing used to generate the pseudo-experiments and the threshold in this case is 0.011215.  One would expect for 95% that the threshold would be ~1.35 once the cross-section is far enough away from 0 that it is essentially unaffected by the boundary. As one reaches the last points in the scan, the threshold starts to get artificially high. This is because the range of the parameter in the fit is the same as the range in the scan.  In the future, these should be independently controlled, but they are not now. As a result, ~50% of pseudo-experiments that have an upward fluctuation end up with muhat = muMax.  Because of this, the upper range of the parameter should be well above the expected upper limit, but not too high or one will need a very large value of `nPointsToScan` to resolve the relevant region. This can be improved, but this is the first version of this script.\n",
    "\n",
    "**Important note**: when the model includes external constraint terms, like a Gaussian constraint to a nuisance parameter centered around some nominal value there is a subtlety. The asymptotic results are all based on the assumption that all the measurements fluctuate, including the nominal values from auxiliary measurements. If these do not fluctuate, this corresponds to an \"conditional ensemble\". The result is that the distribution of the test statistic can become very non-chi^2. This results in thresholds that become very large. This can be seen in the following thought experiment. Say the model is:\n",
    "\n",
    "$$Pois(N | s + b) * G(b0|b,sigma)$$\n",
    "\n",
    "where $G(b0|b,sigma)$ is the external constraint and `b0` is 100. If `N` is also 100 then the profiled value of `b` given `s` is going to be some trade off betwen 100-`s` and `b0`. If `sigma` is `sqrt(N)`, then the profiled value of `b` is probably 100 - `s`/2.  So for `s`=60 we are going to have a profiled value of `b`~70. Now when we generate pseudo-experiments for `s`=60, `b`=70 we will have `N`~130 and the average shat will be 30, not 60. In practice, this is only an issue for values of `s` that are very excluded. For values of `s` near the 95% limit this should not be a big effect. This can be avoided if the nominal values of the constraints also fluctuate, but that requires that those parameters are RooRealVars in the model. This version does not deal with this issue, but it will be addressed in a future version.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#include \"RooWorkspace.h\"\n",
    "#include \"RooSimultaneous.h\"\n",
    "#include \"RooAbsData.h\"\n",
    "\n",
    "#include \"RooStats/ModelConfig.h\"\n",
    "#include \"RooStats/FeldmanCousins.h\"\n",
    "#include \"RooStats/ToyMCSampler.h\"\n",
    "#include \"RooStats/PointSetInterval.h\"\n",
    "#include \"RooStats/ConfidenceBelt.h\"\n",
    "\n",
    "#include \"RooStats/RooStatsUtils.h\"\n",
    "#include \"RooStats/ProfileLikelihoodTestStat.h\"\n",
    "\n",
    "using namespace RooFit;\n",
    "using namespace RooStats;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "auto confidenceLevel = 0.68;\n",
    "auto nPointsToScan = 20;\n",
    "auto nToyMC = 80; // This number is kept low to have a quick calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "auto filename = \"results/example_combined_GaussExample_model.root\";\n",
    "auto workspaceName = \"combined\";\n",
    "auto modelConfigName = \"ModelConfig\";\n",
    "auto dataName = \"obsData\";"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create an example file.\n",
    "The `prepareHistFactory` and `hist2workspace` scripts are in `$ROOTSYS/bin`, which is in `$PATH`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    ".bash\n",
    "prepareHistFactory . >& prepareHistFactory.log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    ".bash\n",
    "hist2workspace config/example.xml >& hist2Workspace.log"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Open the example file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "auto file = TFile::Open(filename);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the workspace from the file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "auto w = (RooWorkspace*) file->Get(workspaceName);\n",
    "if (!w) {\n",
    "    cout << \"Workspace not found\" << endl;\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the model configuration from the file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "auto mc = (ModelConfig*) w->obj(modelConfigName);\n",
    "if (!mc) {\n",
    "    w->Print();\n",
    "    cout << \"ModelConfig was not found\" << endl;\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the data from the file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "auto data = w->data(dataName);\n",
    "if (!data) {\n",
    "    w->Print();\n",
    "    cout << \"Data was not found\" << endl;\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the POI. You may want to adjust the range of your POI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "auto firstPOI = (RooRealVar*) mc->GetParametersOfInterest()->first();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create and use the FeldmanCousins tool to find and plot the 95% confidence interval on the parameter of interest as specified in the model config.\n",
    "\n",
    "REMEMBER, we will change the test statistic so this is NOT a Feldman-Cousins interval."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "FeldmanCousins fc(*data,*mc);\n",
    "fc.SetConfidenceLevel(confidenceLevel);\n",
    "fc.SetNBins(nPointsToScan); // set how many points per parameter of interest to scan\n",
    "fc.CreateConfBelt(true);    // save the information in the belt for plotting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feldman-Cousins is a unified limit by definition but the tool takes care of a few things for us like which values of the nuisance parameters should be used to generate toys. So let's just change the test statistic and realize this is no longer \"Feldman-Cousins\" but is a fully frequentist Neyman-Construction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "auto toymcsampler = (ToyMCSampler*) fc.GetTestStatSampler();\n",
    "ProfileLikelihoodTestStat* testStat = dynamic_cast<ProfileLikelihoodTestStat*>(toymcsampler->GetTestStatistic());\n",
    "testStat->SetOneSided(true);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since this tool needs to throw toy MC the PDF needs to be extended or the tool needs to know how many entries in a dataset per pseudo experiment. In the 'number counting form' where the entries in the dataset are counts, and not values of discriminating variables, the datasets typically only have one entry and the PDF is not extended."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if (!mc->GetPdf()->canBeExtended()) {\n",
    "    if (data->numEntries() == 1)\n",
    "        fc.FluctuateNumDataEntries(false);\n",
    "    else\n",
    "        cout << \"Not sure what to do about this model\" << endl;\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if (mc->GetGlobalObservables()) {\n",
    "    cout << \"will use global observables for unconditional ensemble\" << endl;\n",
    "    mc->GetGlobalObservables()->Print();\n",
    "    toymcsampler->SetGlobalObservables(*mc->GetGlobalObservables());\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now get the interval. This is the most computationally-intensive part."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "PointSetInterval* interval = fc.GetInterval();\n",
    "ConfidenceBelt* belt = fc.GetConfidenceBelt();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print out the interval on the first Parameter of Interest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cout << \"\\n \" << confidenceLevel*100 <<  \"% interval on \" << firstPOI->GetName() << \" is : [\"\n",
    "     << interval->LowerLimit(*firstPOI) << \", \"\n",
    "     << interval->UpperLimit(*firstPOI) << \"] \"\n",
    "     << endl;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get observed UL and value of test statistic evaluated there."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "RooArgSet tmpPOI(*firstPOI);\n",
    "double observedUL = interval->UpperLimit(*firstPOI);\n",
    "firstPOI->setVal(observedUL);\n",
    "double obsTSatObsUL = fc.GetTestStatSampler()->EvaluateTestStatistic(*data,tmpPOI);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ask the calculator which points were scanned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "auto parameterScan = (RooDataSet*) fc.GetPointsToScan();\n",
    "RooArgSet* tmpPoint;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make a histogram of parameter vs. threshold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "TH1F histOfThresholds(\"histOfThresholds\",\"\",\n",
    "                      parameterScan->numEntries(),\n",
    "                      firstPOI->getMin(),\n",
    "                      firstPOI->getMax());\n",
    "histOfThresholds.GetXaxis()->SetTitle(firstPOI->GetName());\n",
    "histOfThresholds.GetYaxis()->SetTitle(\"Threshold\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loop through the points that were tested and ask confidence belt what the upper/lower thresholds were. For FeldmanCousins, the lower cut off is always 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for (Int_t i=0; i<parameterScan->numEntries(); ++i) {\n",
    "    tmpPoint = (RooArgSet*) parameterScan->get(i)->clone(\"temp\");\n",
    "    double arMax = belt->GetAcceptanceRegionMax(*tmpPoint);\n",
    "    double poiVal = tmpPoint->getRealValue(firstPOI->GetName());\n",
    "    histOfThresholds.Fill(poiVal,arMax);\n",
    "}\n",
    "TCanvas c1(\"Results\",\"Results\",1000,800);\n",
    "c1.Divide(2);\n",
    "c1.cd(1);\n",
    "histOfThresholds.SetMinimum(0);\n",
    "histOfThresholds.Draw();\n",
    "c1.cd(2);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we generate the expected bands and power-constraint.\n",
    "\n",
    "First: find parameter point for mu=0, with conditional MLEs for nuisance parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "auto nll = mc->GetPdf()->createNLL(*data);\n",
    "auto profile = nll->createProfile(*mc->GetParametersOfInterest());\n",
    "firstPOI->setVal(0.);\n",
    "profile->getVal(); // this will do fit and set nuisance parameters to profiled values\n",
    "auto poiAndNuisance = new RooArgSet();\n",
    "if (mc->GetNuisanceParameters())\n",
    "    poiAndNuisance->add(*mc->GetNuisanceParameters());\n",
    "poiAndNuisance->add(*mc->GetParametersOfInterest());\n",
    "w->saveSnapshot(\"paramsToGenerateData\",*poiAndNuisance);\n",
    "auto paramsToGenerateData = (RooArgSet*) poiAndNuisance->snapshot();\n",
    "cout << \"\\nWill use these parameter points to generate pseudo data for bkg only\" << endl;\n",
    "paramsToGenerateData->Print(\"v\");\n",
    "\n",
    "RooArgSet unconditionalObs;\n",
    "unconditionalObs.add(*mc->GetObservables());\n",
    "unconditionalObs.add(*mc->GetGlobalObservables()); // comment this out for the original conditional ensemble\n",
    "\n",
    "double CLb = 0;\n",
    "double CLbinclusive = 0;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we generate background only and find distribution of upper limits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "TH1F histOfUL(\"histOfUL\",\"\",100,0,firstPOI->getMax());\n",
    "histOfUL.GetXaxis()->SetTitle(\"Upper Limit (background only)\");\n",
    "histOfUL.GetYaxis()->SetTitle(\"Entries\");\n",
    "\n",
    "for (int imc=0; imc<nToyMC; ++imc) {\n",
    "    // set parameters back to values for generating pseudo data\n",
    "    w->loadSnapshot(\"paramsToGenerateData\");\n",
    "  \n",
    "    RooDataSet* toyData = 0;\n",
    "    // now generate a toy dataset\n",
    "    if(!mc->GetPdf()->canBeExtended()){\n",
    "        if (data->numEntries() == 1)\n",
    "            toyData = mc->GetPdf()->generate(*mc->GetObservables(),1);\n",
    "        else\n",
    "            cout <<\"Not sure what to do about this model\" <<endl;\n",
    "    }\n",
    "    else {\n",
    "       toyData = mc->GetPdf()->generate(*mc->GetObservables(),Extended());\n",
    "    }\n",
    "\n",
    "    // generate global observables\n",
    "    // need to be careful for simpdf\n",
    "    auto simPdf = dynamic_cast<RooSimultaneous*>(mc->GetPdf());\n",
    "    if (!simPdf) {\n",
    "        auto one = mc->GetPdf()->generate(*mc->GetGlobalObservables(), 1);\n",
    "        const RooArgSet *values = one->get();\n",
    "        auto allVars = mc->GetPdf()->getVariables();\n",
    "        *allVars = *values;\n",
    "        delete allVars;\n",
    "        delete values;\n",
    "        delete one;\n",
    "    }\n",
    "    else {\n",
    "        //try fix for sim pdf\n",
    "        auto iter = simPdf->indexCat().typeIterator() ;\n",
    "        RooCatType* tt = NULL;\n",
    "        while ((tt=(RooCatType*) iter->Next())) {\n",
    "            // Get pdf associated with state from simpdf\n",
    "            auto pdftmp = simPdf->getPdf(tt->GetName()) ;\n",
    "\n",
    "            // Generate only global variables defined by the pdf associated with this state\n",
    "            auto globtmp = pdftmp->getObservables(*mc->GetGlobalObservables()) ;\n",
    "            auto tmp = pdftmp->generate(*globtmp,1) ;\n",
    "\n",
    "            // Transfer values to output placeholder\n",
    "            *globtmp = *tmp->get(0) ;\n",
    "\n",
    "            // Cleanup\n",
    "            delete globtmp ;\n",
    "            delete tmp ;\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    // get test stat at observed UL in observed data\n",
    "    firstPOI->setVal(observedUL);\n",
    "    double toyTSatObsUL = fc.GetTestStatSampler()->EvaluateTestStatistic(*toyData,tmpPOI);\n",
    "    \n",
    "    if (obsTSatObsUL < toyTSatObsUL) // not sure about <= part yet\n",
    "        CLb+= (1.)/nToyMC;\n",
    "    if (obsTSatObsUL <= toyTSatObsUL) // not sure about <= part yet\n",
    "        CLbinclusive+= (1.)/nToyMC;\n",
    "\n",
    "    // loop over points in belt to find upper limit for this toy data\n",
    "    double thisUL = 0;\n",
    "    for (Int_t i=0; i<parameterScan->numEntries(); ++i) {\n",
    "        tmpPoint = (RooArgSet*) parameterScan->get(i)->clone(\"temp\");\n",
    "        double arMax = belt->GetAcceptanceRegionMax(*tmpPoint);\n",
    "        firstPOI->setVal( tmpPoint->getRealValue(firstPOI->GetName()) );\n",
    "        double thisTS = fc.GetTestStatSampler()->EvaluateTestStatistic(*toyData,tmpPOI);\n",
    "\n",
    "        if (thisTS<=arMax) {\n",
    "            thisUL = firstPOI->getVal();\n",
    "        }\n",
    "        else {\n",
    "            break;\n",
    "        }\n",
    "    }\n",
    "    histOfUL.Fill(thisUL);\n",
    "\n",
    "    // for few events, data is often the same, and UL is often the same\n",
    "    delete toyData;\n",
    "}\n",
    "histOfUL.Draw();\n",
    "c1.Draw();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now find bands and power constraint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "auto bins = histOfUL.GetIntegral();\n",
    "auto cumulative = (TH1F*) histOfUL.Clone(\"cumulative\");\n",
    "cumulative->SetContent(bins);\n",
    "double band2sigDown, band1sigDown, bandMedian, band1sigUp,band2sigUp;\n",
    "\n",
    "for (int i=1; i<=cumulative->GetNbinsX(); ++i) {\n",
    "    if(bins[i]<RooStats::SignificanceToPValue(2))\n",
    "        band2sigDown=cumulative->GetBinCenter(i);\n",
    "    if(bins[i]<RooStats::SignificanceToPValue(1))\n",
    "        band1sigDown=cumulative->GetBinCenter(i);\n",
    "    if(bins[i]<0.5)\n",
    "        bandMedian=cumulative->GetBinCenter(i);\n",
    "    if(bins[i]<RooStats::SignificanceToPValue(-1))\n",
    "        band1sigUp=cumulative->GetBinCenter(i);\n",
    "    if(bins[i]<RooStats::SignificanceToPValue(-2))\n",
    "        band2sigUp=cumulative->GetBinCenter(i);\n",
    "}\n",
    "\n",
    "cout << \"-2 sigma  band \" << band2sigDown << endl;\n",
    "cout << \"-1 sigma  band \" << band1sigDown << \" [Power Constraint)]\" << endl;\n",
    "cout << \"median of band \" << bandMedian << endl;\n",
    "cout << \"+1 sigma  band \" << band1sigUp << endl;\n",
    "cout << \"+2 sigma  band \" << band2sigUp << endl;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print out the interval on the first Parameter of Interest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cout << \"\\nobserved \" << confidenceLevel*100 <<  \"% upper-limit \"<< interval->UpperLimit(*firstPOI) <<endl;\n",
    "cout << \"CLb strict [P(toy>obs|0)] for observed \" << confidenceLevel*100 <<  \"% upper-limit \"<< CLb <<endl;\n",
    "cout << \"CLb inclusive [P(toy>=obs|0)] for observed \" << confidenceLevel*100 <<  \"% upper-limit \"<< CLbinclusive <<endl;\n",
    "\n",
    "delete profile;\n",
    "delete nll;"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ROOT Prompt",
   "language": "c++",
   "name": "root"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
